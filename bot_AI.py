import telebot
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import os
from dotenv import load_dotenv
import timm
import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω –±–æ—Ç–∞
load_dotenv()


bot = telebot.TeleBot(str(os.getenv("API")) + ":" + str(os.getenv("API2")))

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞
CONFIG_PATH = "config.json"
with open(CONFIG_PATH, "r") as f:
    config = json.load(f)

IMG_SIZE = config["img_size"]
BACKBONE = config["backbone"]
NUM_CLASSES = config["num_classes"]  # –í–ê–ñ–ù–û: —ç—Ç–æ –∫–ª—é—á–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ!

# –¢–æ—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ (–∫–∞–∫ –≤ train.py)
class PlantModel(nn.Module):
    def __init__(self, backbone="efficientnet_b0", num_classes=3):
        super().__init__()
        self.backbone = timm.create_model(
            backbone, 
            pretrained=False, 
            num_classes=0, 
            global_pool="avg"
        )
        in_features = self.backbone.num_features
        self.classifier = nn.Linear(in_features, num_classes)
        self.regressor = nn.Linear(in_features, 1)  # –¥–ª—è –≤—ã—Å–æ—Ç—ã, –Ω–æ –º—ã –Ω–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

    def forward(self, x):
        feats = self.backbone(x)
        cls_out = self.classifier(feats)
        reg_out = torch.sigmoid(self.regressor(feats))
        return cls_out, reg_out

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = PlantModel(backbone=BACKBONE, num_classes=NUM_CLASSES).to(device)

MODEL_PATH = "plant_model.pth"
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.eval()

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
])

# –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤
label_map = {0: "not_plant", 1: "plant_healthy", 2: "plant_unhealthy"}

def predict(image_path):
    image = Image.open(image_path).convert("RGB")
    tensor = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        cls_out, reg_out = model(tensor)
        cls_idx = cls_out.argmax(dim=1).item()
        confidence = torch.softmax(cls_out, dim=1)[0][cls_idx].item()
    
    label = label_map[cls_idx]
    return label, confidence

@bot.message_handler(commands=["start"])
def start(message):
    bot.reply_to(message, "üå± –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ —Ä–∞—Å—Ç–µ–Ω–∏—è ‚Äî —è —Å–∫–∞–∂—É:\n- –≠—Ç–æ —Ä–∞—Å—Ç–µ–Ω–∏–µ –∏–ª–∏ –Ω–µ—Ç?\n- –ó–¥–æ—Ä–æ–≤–æ–µ –æ–Ω–æ –∏–ª–∏ –±–æ–ª—å–Ω–æ–µ?")

@bot.message_handler(content_types=["photo"])
def handle_photo(message):
    try:
        file_info = bot.get_file(message.photo[-1].file_id)
        downloaded = bot.download_file(file_info.file_path)
        file_path = f"temp_{message.chat.id}.jpg"
        
        with open(file_path, "wb") as f:
            f.write(downloaded)
        
        label, confidence = predict(file_path)
        os.remove(file_path)
        
        if label == "not_plant":
            response = "‚ùå –≠—Ç–æ –Ω–µ —Ä–∞—Å—Ç–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—Ç–µ–Ω–∏–µ –ø–æ–±–ª–∏–∂–µ."
        else:
            status = "–∑–¥–æ—Ä–æ–≤–æ–µ" if label == "plant_healthy" else "–±–æ–ª—å–Ω–æ–µ"
            response = (
                f"‚úÖ –≠—Ç–æ —Ä–∞—Å—Ç–µ–Ω–∏–µ!\n"
                f"–°–æ—Å—Ç–æ—è–Ω–∏–µ: {status}\n"
                f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}"
            )
        
        bot.reply_to(message, response)
    
    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ.")

print("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –ñ–¥—É —Ñ–æ—Ç–æ...")
bot.polling(none_stop=True)